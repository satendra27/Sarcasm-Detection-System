{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "420dd7f9-c10b-4254-a6ce-782c69aa7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de266389-4caa-4755-9b0b-3d705cd18aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sarcasm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b2aaa56-702d-4e5f-91c5-74780a050761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>irony</th>\n",
       "      <th>satire</th>\n",
       "      <th>understatement</th>\n",
       "      <th>overstatement</th>\n",
       "      <th>rhetorical_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Today my pop-pop told me I was not ‚Äúforced‚Äù to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              tweet  sarcastic  \\\n",
       "0           0  The only thing I got from college is a caffein...          1   \n",
       "1           1  I love it when professors draw a big question ...          1   \n",
       "2           2  Remember the hundred emails from companies whe...          1   \n",
       "3           3  Today my pop-pop told me I was not ‚Äúforced‚Äù to...          1   \n",
       "4           4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1   \n",
       "\n",
       "   sarcasm  irony  satire  understatement  overstatement  rhetorical_question  \n",
       "0      0.0    1.0     0.0             0.0            0.0                  0.0  \n",
       "1      1.0    0.0     0.0             0.0            0.0                  0.0  \n",
       "2      0.0    1.0     0.0             0.0            0.0                  0.0  \n",
       "3      1.0    0.0     0.0             0.0            0.0                  0.0  \n",
       "4      1.0    0.0     0.0             0.0            0.0                  0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27bf72b7-93d2-438a-8def-954da79d4841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not ‚Äúforced‚Äù to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sarcastic\n",
       "0  The only thing I got from college is a caffein...          1\n",
       "1  I love it when professors draw a big question ...          1\n",
       "2  Remember the hundred emails from companies whe...          1\n",
       "3  Today my pop-pop told me I was not ‚Äúforced‚Äù to...          1\n",
       "4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"tweet\",\"sarcastic\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dbd7a90-adb7-4f3e-acb2-5c56b3fa2dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet        1\n",
       "sarcastic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77d24c49-061d-48db-a9ad-7b3e74a813b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd7c81e1-7efa-4796-ade4-f35d2572972b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet        0\n",
       "sarcastic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee64c9e-1181-446c-a904-d4e588fbe418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afd403a1-594a-4151-bd99-149f2c0733a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\krishna\n",
      "[nltk_data]     computers\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\krishna\n",
      "[nltk_data]     computers\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\krishna\n",
      "[nltk_data]     computers\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892df5ed-95d8-4144-aeab-ea5f006ad628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ad61b8-9591-4f73-aa9a-fb4985cbc8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords   #nltk is library corpus is class and stopwords is function\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from contractions import fix # don't ===> do not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d3a39c4-0e7b-415d-804d-dbe0cdb4a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07bd554d-77d1-4695-8d5b-9edc99cba57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "133893a3-9b4b-45e0-acbf-ddf7035e8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_advanced(text):\n",
    "    # Expand contractions\n",
    "    text = fix(text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back to a single string\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    \n",
    "    # Remove excessive whitespaces\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8332011a-6e86-4d7f-a04d-cf35cc5abd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(clean_text_advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6297f4a9-a0d5-4e25-b580-56955ef72922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thing got college caffeine addiction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love professor draw big question mark next ans...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>remember hundred email company covid started g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>today poppop told ‚Äú forced ‚Äù go college üôÉ okay...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>volphancarol littlewhitty mysticalmanatee also...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>population spike chicago 9 month ridiculous</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>would think second last english class year pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>finally surfacing holiday scotland difficult d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>could prouder today well done every student go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>overheard 13 year old game friend smell like t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3467 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  sarcastic\n",
       "0                  thing got college caffeine addiction          1\n",
       "1     love professor draw big question mark next ans...          1\n",
       "2     remember hundred email company covid started g...          1\n",
       "3     today poppop told ‚Äú forced ‚Äù go college üôÉ okay...          1\n",
       "4     volphancarol littlewhitty mysticalmanatee also...          1\n",
       "...                                                 ...        ...\n",
       "3463        population spike chicago 9 month ridiculous          0\n",
       "3464  would think second last english class year pro...          0\n",
       "3465  finally surfacing holiday scotland difficult d...          0\n",
       "3466  could prouder today well done every student go...          0\n",
       "3467  overheard 13 year old game friend smell like t...          0\n",
       "\n",
       "[3467 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "186bda18-1b5b-4466-a104-e8d7af1a11b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sarcastic\n",
       "0    2600\n",
       "1     867\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sarcastic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcbb504-a18f-4cd7-9d52-015347671d53",
   "metadata": {},
   "source": [
    "### Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91a3be51-6b09-4f03-90f2-8cbfc6b3f0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Class Distribution:\n",
      " sarcastic\n",
      "1    2600\n",
      "0    2600\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# Splitting the data into features and labels\n",
    "X = df['tweet'].values.reshape(-1, 1)  # Reshaping for the oversampler\n",
    "y = df['sarcastic']\n",
    "# Applying Random Oversampling\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_balanced, y_balanced = oversampler.fit_resample(X, y)\n",
    "\n",
    "# Creating a balanced DataFrame\n",
    "df = pd.DataFrame({'tweet': X_balanced.flatten(), 'sarcastic': y_balanced})\n",
    "\n",
    "# Check the new class distribution\n",
    "print(\"\\nBalanced Class Distribution:\\n\", df['sarcastic'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c9aacfe-f7ae-4b54-a58b-79cfaf01c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer() \n",
    "X = tfidf.fit_transform(df['tweet'])\n",
    "\n",
    "#  Define target variable\n",
    "y = df['sarcastic']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66b7ff4f-d58b-4724-a832-9d4efc819f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)  # `with_mean=False` due to sparse matrix\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63b188fb-79d7-4d43-bc4a-1d62330ad9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.46%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88       493\n",
      "           1       0.87      0.91      0.89       547\n",
      "\n",
      "    accuracy                           0.88      1040\n",
      "   macro avg       0.89      0.88      0.88      1040\n",
      "weighted avg       0.89      0.88      0.88      1040\n",
      "\n",
      "Confusion Matrix:\n",
      " [[420  73]\n",
      " [ 47 500]]\n"
     ]
    }
   ],
   "source": [
    "# 3. Train SVM Model\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "model = SVC(kernel='linear')  # Linear kernel is common for text classification\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 5. Evaluate the Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4456a04e-47b4-49a8-af88-e39749010239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 90.67%\n",
      "Classification Report (Random Forest):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       493\n",
      "           1       0.93      0.89      0.91       547\n",
      "\n",
      "    accuracy                           0.91      1040\n",
      "   macro avg       0.91      0.91      0.91      1040\n",
      "weighted avg       0.91      0.91      0.91      1040\n",
      "\n",
      "Confusion Matrix (Random Forest):\n",
      " [[454  39]\n",
      " [ 58 489]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf * 100:.2f}%\")\n",
    "print(\"Classification Report (Random Forest):\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix (Random Forest):\\n\", confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c682268b-4326-4101-a335-53b7c36ac4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sarcasm(new_headline):\n",
    "    cleaned_headline = clean_text_advanced(new_headline)  \n",
    "    transformed_headline = tfidf.transform([cleaned_headline])\n",
    "    prediction = model.predict(transformed_headline)\n",
    "    \n",
    "    if prediction == 1:\n",
    "        return \"Sarcastic\"\n",
    "    else:\n",
    "        return \"Not Sarcastic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f075bcf-4823-473c-90dd-b933632331d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for comment: 'Oh great, another Monday! I just love waking up early after the weekend.' -> \n",
      " Not Sarcastic\n"
     ]
    }
   ],
   "source": [
    "# Example usage of detection system\n",
    "test_headline = \"Oh great, another Monday! I just love waking up early after the weekend.\"\n",
    "\n",
    "print(f\"Prediction for comment: '{test_headline}' -> \\n {detect_sarcasm(test_headline)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74afb1f2-2d96-4f3f-a927-9f037059e021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for comment: 'Oh, how thoughtful! I really needed someone to explain the obvious to me.' -> \n",
      " Not Sarcastic\n"
     ]
    }
   ],
   "source": [
    "# Example usage of detection system\n",
    "test_headline = \"Oh, how thoughtful! I really needed someone to explain the obvious to me.\"\n",
    "print(f\"Prediction for comment: '{test_headline}' -> \\n {detect_sarcasm(test_headline)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25581655-bf1c-4840-92c9-233e8a157500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model,open(\"model.pkl\",'wb'))\n",
    "pickle.dump(tfidf,open(\"tfidf.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaec2d1-92ec-4930-a0f0-1bcc1f120cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
